from collections import defaultdict
import itertools
import logging
import os
import re
import uuid
from typing import List

from datasets import Dataset as HuggingFaceDataset, concatenate_datasets
import pandas as pd
from tqdm import tqdm

from src.data.dataset import Dataset, PrunedConceptDataset, VerbalizedExtractionDataset
from src.ontology.snomed import Snomed

logger = logging.getLogger(__name__)

standard_domain_mapping = {
    'ecg': 'ECG',
    'ECG': 'ECG',
    'physician_': 'Physician',
    'Nursing': 'Nursing',
    'nursing': 'Nursing',
    'nursing_other': 'Nursing',
    'radiology': 'Radiology',
    'Radiology': 'Radiology'
}


class HumanEvaluationDataset(Dataset):
    """
    Dataset needed to perform a human evaluation (which will generate the right folder structure for human evaluation)


    The columns should be, for each domain and method combinaison :
        - hadm_id : Admission id in MIMIC
        - notes : Clinical notes associated to the admission
        - {method}_{domain}_structured : Extractions pruned according to domain (as a dictionary)
        - {method}_{domain}_summary : Final summary generated by this method for this domain
    """

    def __init__(self, dataset_path = None, data = None):
        """
        Args:
            domains: List of domains to evaluate (only names according to `standard_domain_mapping` at top of the file)
            methods: List of methods to consider (constrained, beam, normal)
            dataset_path: Path to dataset (see `Dataset`)
            data: DataFramce (see `Dataset`)
        """
        super().__init__(dataset_path, data)

        self.verify()

    def verify(self):
        for column in ['id', 'notes', 'admission_id', 'structured_summary', 'summary', 'method', 'domain', 'relevance', 'groundedness', 'completeness', 'coherence', 'fluency']:
            assert column in self.data.columns, f'Column {column} should be in the dataset'
                     
class HumanEvaluation:

    """
    In order to perform human evaluation, we need to have a dataset with the following columns:

    - id: Unique identifier for the sample generated
    - hadm_id: Unique identifier for the admission in the MIMIC-III dataset
    - clinical_notes : Clinical notes that were used to generate the summary
    - summary: Summary that was generated by the model
    - expected_domain : The domain that the summary is expected to be relevant to
    - relevance : Score (1-5) which indicates how relevant the summary is to the expected domain
        1 being that the summary is not relevant to the expected domain at all
        5 being that all the information in the summary is relevant to the expected domain
    - groundedness : Score (1-5) which indicates how grounded the summary is
        1 being that the summary is not grounded in the clinical notes at all
        5 being that the summary is fully grounded in the clinical notes
    - completeness : Score (1-5) which indicates how much of the information in the clinical notes is present in the summary 
        1 being that the summary contains none of the information in the clinical notes
        5 being that the summary contains all the information in the clinical notes that is relevant to the expected domain
    - method : Which method was used to generate the summary
    - coherence : Score (1-5) which indicates how coherent the summary is with itself
        1 being that the summary is not coherent at all
        5 being that the summary is fully coherent
    - fluency : Score (1-5) which indicates how fluent the summary is
        1 being that the summary is not fluent at all (bullet points, etc.)
        5 being that the summary is fully fluent (no bullet points, etc.)
    """

    def __init__(self, domains: List[str], methods: List[str], snomed: Snomed):
        """
        Args:
            domains: List of domains to consider
            methods: List of methods to consider
            pruned_dataset_paths: Path to pruned dataset (must be valid PrunedConceptDataset containing the methods and domains)
            verbalized_dataset_paths: Path to verbalized dataset (must be valid VerbalizedExtractionDataset containing the methods and domains)
            snomed: Snomed ontology
        """
        self.domains = domains
        self.methods = methods
        self.snomed = snomed

        self.verify_domains()

    def verify_domains(self):
        valid_domains = list(standard_domain_mapping.keys())
        for domain in self.domains:
            assert domain in valid_domains, f'Domain {domain} not recognized, here is the list of valid domains {valid_domains}'

    def create_columns(self):
        pruned_columns = []
        verbalized_columns = []
        for method in self.methods:
            for domain in self.domains:
                pruned_columns.append(f'{method}_{domain}')
                verbalized_columns.append(f'{method}_{domain}_verbalized')
        return pruned_columns, verbalized_columns

    def generate(self, pruned_dataset_paths: List[str], verbalized_dataset_paths: List[str]):

        final_dataset: HuggingFaceDataset = None

        for pruned_dataset_path, verbalized_dataset_path in zip(pruned_dataset_paths, verbalized_dataset_paths):
            current_dataset = self.generate_single(pruned_dataset_path, verbalized_dataset_path)
            final_dataset = concatenate_datasets(list(filter(lambda x: x is not None, [final_dataset, current_dataset])))

        return final_dataset
    
    def generate_single(self, pruned_dataset_path: str, verbalized_dataset_path: str, remove_same_exractions: bool = True):

        pruned_columns, verbalized_columns = self.create_columns()

        self.pruned_dataset = PrunedConceptDataset(columns=pruned_columns, dataset_path=pruned_dataset_path)
        self.verbalized_dataset = VerbalizedExtractionDataset(columns=verbalized_columns, dataset_path=verbalized_dataset_path)

        dataset = defaultdict(list)
        notes_per_admission_id = self.pruned_dataset.data.groupby('HADM_ID')['TEXT'].aggregate(self.admission_to_prompt)

        for i in tqdm(range(len(self.verbalized_dataset.data)), desc='Generating human evaluation samples'):
            admission_id = self.verbalized_dataset.data['HADM_ID'].iloc[i]
            notes = notes_per_admission_id[admission_id]

            for method in self.methods:
                for domain in self.domains:
                    
                    pruned_col = f'{method}_{domain}'
                    verbalized_col = pruned_col + '_verbalized'
                    summary = self.verbalized_dataset.data[verbalized_col].iloc[i]
                    structured_summary = self.get_pruned_extractions_of_admission(admission_id, pruned_col, remove_same_exractions)

                    if not self.summary_valid(summary) or not self.summary_valid(structured_summary):
                        continue

                    dataset['id'].append(str(uuid.uuid4()))
                    dataset['notes'].append(notes)
                    dataset['admission_id'].append(admission_id)
                    dataset['structured_summary'].append(structured_summary)
                    dataset['summary'].append(summary)
                    dataset['method'].append(method)
                    dataset['domain'].append(standard_domain_mapping[domain])
                    dataset['relevance'].append(0)
                    dataset['groundedness'].append(0)
                    dataset['completeness'].append(0)
                    dataset['coherence'].append(0)
                    dataset['fluency'].append(0)

        return HuggingFaceDataset.from_dict(dataset)
    
    def summary_valid(self, summary: str):
        return summary is not None and isinstance(summary, str) and len(summary) > 0

    def admission_to_prompt(self, clinical_notes_series):
        return '\n\n'.join([f'### Clinical note {i+1}\n{note}' for i, note in enumerate(clinical_notes_series.tolist())])

    def get_pruned_extractions_of_admission(self, admission_id: float, pruned_domain_col: str, remove_same_extractions: bool = True):
        """
        Returns the pruned extractions according to a domain of an admission. This assumes that `pruned_domain_col` contains
        the pruned extractions of a clinical note
        """
        def admission_to_prompt(clinical_notes_series):
            clinical_notes = clinical_notes_series.tolist()

            
            note_strings = []
            for _, note in enumerate(clinical_notes):
                extraction_set = set([])
                clinical_note_string = ''

                for concept_id, extraction in note.items():
                    if extraction == 'N/A':
                        continue

                    if remove_same_extractions and extraction.lower().strip() in extraction_set:
                        continue

                    concept_label = self.snomed.get_label_from_id(concept_id)
                    clinical_note_string += f'- {concept_label} : {extraction}\n'
                    extraction_set.add(extraction.lower().strip())

                if len(clinical_note_string.strip()) > 0:
                    note_strings.append(clinical_note_string)
            if len(note_strings) == 0:
                return 'N/A'

            note_strings = list(filter(lambda x: x != '', note_strings))
            note_strings = [f'### Clinical note {i+1}\n{note}' for i, note in enumerate(note_strings)]
            return '\n\n'.join(note_strings)

        return self.pruned_dataset.data.groupby('HADM_ID')[pruned_domain_col].aggregate(admission_to_prompt)[admission_id]


class HumanEvaluationFilesGenerator:

    CLINICAL_NOTES_FILENAME = 'notes'
    SUMMARY_FILENAME = 'summary'
    STRUCTURED_SUMMARY_FILENAME = 'structured_summary'


    def __init__(self, human_evaluation_dataset_path: str = None, human_evaluation_dataset: pd.DataFrame = None):
        self.dataset = HumanEvaluationDataset(dataset_path=human_evaluation_dataset_path, data=human_evaluation_dataset)
    
    def generate_folder_structure(self, path: str):
        """
        Will generate the folder structure to facilitate the evaluation by humans

        Args:
            path: Path where the folders and files will be stored
        """

        if path[-1] != '/':
            path += '/'

        if not os.path.exists(path):
            os.makedirs(path, exist_ok=True)

        domains = self.dataset.data['domain'].unique()

        for domain in domains:
            os.makedirs(path + domain, exist_ok=True)

        def row_to_folder(row):

            excel_path = path + '/' + str(row['domain']) + '/' + str(row['folder_id']) + '.xlsx'

            structured_summary = pd.DataFrame({'Structured Summary': [row['structured_summary']]})
            clinical_note = pd.DataFrame({'Clinical Notes': [row['notes']]})
            summary = pd.DataFrame({'Summary': [row['summary']]})
            evaluation = pd.DataFrame({
                'Criteria': ['Relevance (/5)', 'Groundedness (/5)', 'Completeness (/5)', 'Coherence (/5)', 'Fluency (/5)'],
                'Score': [0, 0, 0, 0, 0],
                'Comments': ['', '', '', '', '']
            })

            with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:
                # Write dataframes to Excel sheets
                clinical_note.to_excel(writer, sheet_name='Clinical Notes', index=False)
                structured_summary.to_excel(writer, sheet_name='Structured Summary', index=False)
                summary.to_excel(writer, sheet_name='Summary', index=False)
                evaluation.to_excel(writer, sheet_name='Evaluation', index=False)

                # Get workbook and worksheet objects for formatting
                workbook = writer.book
                
                # Format for text cells - enable text wrapping, set large font size (20), and set valign
                text_format = workbook.add_format({
                    'text_wrap': True, 
                    'valign': 'top',
                    'font_size': 16
                })
                
                header_format = workbook.add_format({
                    'bold': True, 
                    'border': 1, 
                    'bg_color': '#D9E1F2',
                    'font_size': 16
                })
                
                eval_format = workbook.add_format({
                    'border': 1,
                    'font_size': 16
                })

                # Format cell sizes
                summary_sheet = writer.sheets['Structured Summary']
                summary_sheet.set_column('A:A', 200, text_format) # Make column very wide
                summary_sheet.set_row(1, 5000)  # Set row height to be tall
                
                notes_sheet = writer.sheets['Clinical Notes']
                notes_sheet.set_column('A:A', 200, text_format)
                notes_sheet.set_row(1, 5000)
                
                summary_sheet = writer.sheets['Summary']
                summary_sheet.set_column('A:A', 200, text_format)
                summary_sheet.set_row(1, 5000)
                
                eval_sheet = writer.sheets['Evaluation']
                eval_sheet.set_column('A:A', 20) # Criteria column
                eval_sheet.set_column('B:B', 10) # Score column
                eval_sheet.set_column('C:C', 40, text_format) # Comments column
                
                # Apply formatting to evaluation headers
                for col_num, header in enumerate(['Criteria', 'Score', 'Comments']):
                    eval_sheet.write(0, col_num, header, header_format)
                
                # Apply formatting to evaluation cells
                for row_num in range(1, 6):
                    eval_sheet.write(row_num, 1, 0, eval_format) # Score cells
                    eval_sheet.write(row_num, 2, '', eval_format) # Comments cells

        self.dataset.data['folder_id'] = list(range(len(self.dataset.data)))
        for _, row in self.dataset.data.iterrows():
            row_to_folder(row)

        self.dataset.data.to_csv(path + 'human_evaluation.csv', index=False)
